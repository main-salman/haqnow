# OPTIMIZED Base image - Target: <1GB  
# Build: docker buildx build --platform linux/amd64 -f Dockerfile.base -t ghcr.io/main-salman/backend-base:latest --push .

FROM python:3.11-slim

WORKDIR /app

# Install ONLY essential system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    tesseract-ocr \
    tesseract-ocr-ara \
    poppler-utils \
    libjpeg62-turbo \
    libpng16-16 \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# Install CPU-only PyTorch FIRST from PyTorch's CPU wheel index
# This MUST happen before any package that depends on torch
RUN pip install --no-cache-dir \
    torch==2.1.2+cpu \
    torchvision==0.16.2+cpu \
    --index-url https://download.pytorch.org/whl/cpu

# Now install sentence-transformers - it will use the already-installed CPU torch
COPY requirements.txt ./
RUN pip install --no-cache-dir sentence-transformers==2.2.2 \
    && pip install --no-cache-dir -r requirements.txt \
    && pip cache purge

# Verify no NVIDIA packages snuck in, remove if any
RUN pip uninstall -y nvidia-cublas-cu12 nvidia-cuda-cupti-cu12 nvidia-cuda-nvrtc-cu12 \
    nvidia-cuda-runtime-cu12 nvidia-cudnn-cu12 nvidia-cufft-cu12 nvidia-curand-cu12 \
    nvidia-cusolver-cu12 nvidia-cusparse-cu12 nvidia-nccl-cu12 nvidia-nvtx-cu12 \
    nvidia-nvjitlink-cu12 nvidia-cusparselt-cu12 nvidia-cufile-cu12 nvidia-nvshmem-cu12 \
    triton 2>/dev/null || true

# Clean up
RUN find /usr/local/lib/python3.11 -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true \
    && find /usr/local/lib/python3.11 -type d -name tests -exec rm -rf {} + 2>/dev/null || true \
    && rm -rf /tmp/* /var/tmp/* /root/.cache

ENV SENTENCE_TRANSFORMERS_HOME=/tmp/.cache/st
ENV TRANSFORMERS_CACHE=/tmp/.cache/tf
ENV HF_HOME=/tmp/.cache/hf
